今天是入职百度的第9️⃣天，记录一下今天的历程。

## 大致流程

```mermaid
graph LR
    A(创建数据集)
    B(模型训练)
    C(模型参数调整)
    A --> B --> C
```

今天的学习内容大致如下：
- 模型微调方法：Post Pretrain、SFT、SFT-LoRA及其相关训练数据格式
- 模型参数的学习与调整

---
接下来一一介绍每个部分：

## 数据集
根据大模型开发说明，我们即可创建自己的数据集。
需要说明的一点是要好好看说明哦，由于我没有仔细看说明，简单的将训练数据与测试数据命名为train.json、test.json且分别放在了两个文件夹下，且json格式为：
```json
{
        "system": "你精通query分类，query类别有：......，请判断下面这个query属于哪一类。",
        "src": [
            "什么材质的衬衫比较有质感"
        ],
        "tgt": [
            "生活和情感"
        ]
    }
```
导致运行时报错：
![image](https://github.com/user-attachments/assets/e025b2a6-ce38-42ff-befc-484e01e9d3a9)
因此大家一定要细心细心再细心‼️，不然只会白白浪费时间⏰。
再次审视文档，我将文件命名为train.json、dev.json，且每行为一条 jsonline：
```json
{"system": "你精通query分类，query类别有：......，请判断下面这个query属于哪一类。", "src": "合租室友带人回来长期住", "tgt": "生活和情感"}
```

## 模型微调方法
本次模型训练主要尝试了SFT与SFT-LoRA，其特点分别如下
- SFT：有监督微调（Supervised Fine-Tuning）在预训练语言模型的基础上使用有标签的数据集进行进一步的微调，以适应特定的下游任务。其依赖于**高质量的标注数据**。
- SFT-LoRA：LoRA（Low-Rank Adaption）在SFT的基础上利用低秩矩阵分解的技术，仅需要微调少量参数便能完成模型微调。因此训练时能够降低所需要的资源。

虽然本次并没有使用Post Pretrain，但是也要简单介绍一下这个方法：
- Post Pretrain：后预训练是在预训练模型的基础上，针对特定领域数据进行无监督学习。特点是需要更多专业化的数据来增强模型在特定领域的效果。

因为我们的数据集是人工已标注的query，因此我们采用SFT与SFT-Lora方法对模型进行微调。

## 模型参数调整
准备好了数据集与微调方法后，模型能顺利跑同，且训练有一定的效果，

## 其他
- 今天发的不是水果，算是蔬菜吧，是...是...是一根黄瓜🥒，原谅我没绷住🤣。
![WechatIMG26](https://github.com/user-attachments/assets/a88051cd-db9f-47b5-abbc-ad5e706e43e4)

## 总结
