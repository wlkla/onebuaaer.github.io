今天是入职百度的第9️⃣天，记录一下今天的历程。

## 大致流程

```mermaid
graph LR
    A(创建数据集)
    B(模型训练)
    C(模型参数调整)
    A --> B --> C
```

今天的学习内容大致如下：
- 模型微调方法：Post Pretrain、SFT、SFT-LoRA及其相关训练数据格式
- 模型参数的学习与调整

---
接下来一一介绍每个部分：

## 数据集
根据大模型开发说明，我们即可创建自己的数据集。
需要说明的一点是要好好看说明哦，由于我没有仔细看说明，简单的将训练数据与测试数据命名为train.json、test.json且分别放在了两个文件夹下，且json格式为：
```json
{
        "system": "你精通query分类，query类别有：......，请判断下面这个query属于哪一类。",
        "src": [
            "什么材质的衬衫比较有质感"
        ],
        "tgt": [
            "生活和情感"
        ]
    }
```
导致运行时报错：
![image](https://github.com/user-attachments/assets/e025b2a6-ce38-42ff-befc-484e01e9d3a9)
因此大家一定要细心细心再细心‼️，不然只会白白浪费时间⏰。
再次审视文档，我将文件命名为train.json、dev.json，且每行为一条 jsonline：
```json
{"system": "你精通query分类，query类别有：......，请判断下面这个query属于哪一类。", "src": "合租室友带人回来长期住", "tgt": "生活和情感"}
```

## 模型微调方法
本次模型训练主要尝试了SFT与SFT-LoRA，其特点分别如下：
- SFT：有监督微调（Supervised Fine-Tuning）在预训练语言模型的基础上使用有标签的数据集进行进一步的微调，以适应特定的下游任务。其依赖于**高质量的标注数据**。
- SFT-LoRA：LoRA（Low-Rank Adaption）在SFT的基础上利用低秩矩阵分解的技术，仅需要微调少量参数便能完成模型微调。因此训练时能够降低所需要的资源。

虽然本次并没有使用Post Pretrain，但是也要简单介绍一下这个方法：
- Post Pretrain：后预训练是在预训练模型的基础上，针对特定领域数据进行无监督学习。特点是需要更多专业化的数据来增强模型在特定领域的效果。

因为我们的数据集是人工已标注的query，因此我们采用SFT与SFT-LoRA方法对模型进行微调。

## 模型参数调整
准备好了数据集与微调方法后，就准备模型训练了，在训练了半个多小时后看到了一个鲜红的**失败**，通过检查日志，发现报错为：
![image](https://github.com/user-attachments/assets/f0e4297f-b390-4085-a4a7-1c80f9208684)
因此开始调整参数**微调方法**、**机器卡数**与**batch_size**
- 将微调方法从STF变为STF-LoRA，训练成功🥰
- 将机器卡数从4卡调为8卡，发现资源不足，任务一直无法进行，参数调整失败🫠
- 将batch_size从8调为4，搭配STF-LoRA成功🥰

运行效果如下：
![image](https://github.com/user-attachments/assets/09a4027b-3a58-4fcf-a9cc-177f95baf441)
由于仅对query进行一级分类，所以正确率在90%以上。等这个模型训练完毕可能就进入二级行业分类，可能正确率瞬间就下去了。

接下来就是其他各种参数的调整，比如学习率、迭代轮数等，又训练了多个模型，详细过程与参数不便详细介绍，因此略过。

## 其他
- 百度码神培训已经结束，我也有幸获得了两个奖品：结课奖🏅和幸运奖，也是拿到了我的第一个小熊
![image](https://github.com/user-attachments/assets/3cb0a946-cbab-4720-8b3f-30d1502126fd)
- 今天再次查看我的徽章，发现又多了两个：**码神**和**云开发体验官**
![image](https://github.com/user-attachments/assets/88ddbfac-8e47-4783-985f-769e71ba14eb)
- 今天发的不是水果，算是蔬菜吧，是一根黄瓜🥒，原谅我没绷住🤣。

## 总结
今天学习了如何新建fleetx任务（就是上面的模型训练任务），并学会使用一些微调方法以及成功训练了一部分模型。通过对各种参数的微调，也是对大模型的作用机制有了更加深入的了解。