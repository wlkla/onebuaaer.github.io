今天是入职百度的第1️⃣1️⃣天，记录一下今天的历程。

## 大致流程

```mermaid
graph LR
    A(数据集修改)
    B(模型训练)
    C(模型部署)
    A --> B --> C
```

昨天模型部署后的使用体验简直一塌糊涂😩，因此决定从头开始重新再来，第一步就是创建一个更加合适的数据集。

---
接下来一一介绍每个部分：

## 数据集创建
之前的数据集格式为：
```json
{"system": "你精通query分类，query类别有：......，请判断下面这个query属于哪一类。", "src": "合租室友带人回来长期住", "tgt": "生活和情感"}
```
这样就导致每次只输入query时模型并不会执行分类任务，而是转而回答query对应的问题。因此经过思考，我决定将数据集改为如下格式：
```json
{"system": "你是一个query分类机器人，query类别有......，你能正确理解query意思并正确分类。", "src": "query为：“转向助力系统有哪些”，请判断其属于哪一类", "tgt": "交通出行"}
```

## 模型训练及部署
在模型训练时，我也进行了调整，主要针对以下几个问题：
- 第一个问题：分类时正确率低
针对这个问题，我改变了训练方式，首先我仅提取两类数据对模型进行训练，此时模型正确率几乎能达到100%，这也印证了一点：分类正确率低的其中一点原因是因为label之间界限模糊，导致分类不稳定。之后我逐渐增加label数量并不断调整参数，我并没有一直增加下去，而是及时做出了第二个调整⬇️
- 第二个问题：模型不稳定，回答混乱
简单举个例子⬇️：可以看出前面还能正常回答（不看正确率），但是问了两三个问题后模型就不稳定了，回答开始混乱。因此我及时做出调整，修改模型，选择了ChatGLM。
```plaintext
[
0:  {
role:  "user",
utterance:  "你是一个query分类机器人，query类别有......，你能正确理解query意思并正确分类。query为：“什么材质的衬衫比较有质感”，请判断其属于哪一类"
} ,
1:  {
role:  "bot",
utterance:  "这个query属于“生活服务”类别。<br>"
} ,
......
6:  {
role:  "user",
utterance:  "你是一个query分类机器人，query类别有......，你能正确理解query意思并正确分类。query为：“小米电视多少钱一台”，请判断其属于哪一类"
} ,
7:  {
role:  "bot",
utterance:  "��制造、生活和情感、政务、小说、信息技术及在线工具查询、软件、旅游出行"
} ,
8:  {
role:  "user",
utterance:  "你是一个query分类机器人，query类别有......，你能正确理解query意思并正确分类。query为：“韩国演艺圈悲惨事件”，请判断其属于哪一类"
} ,
9:  {
role:  "bot",
utterance:  "��制造、生活和情感、政务、小说、信息技术及在线工具查询、软件、旅游出行"
} ,
......
]
```
在做出以上修改以后发现效果十分不错，感觉主要是ChatGLM模型比较好吧，然后开始再次逐渐增加label数量直到将所有label纳入数据集，并训练出了第一个效果较好的模型：
![image](https://github.com/user-attachments/assets/78848cba-c107-4ab8-9f9a-3fe6f841dc49)
虽然训练效果很好，但是与之前我认为很好的llama2相比也没太大区别，因此主要还是看模型部署后的实际效果如何：
```plaintext
[
0:  {
role:  "user",
utterance:  "你是一个query分类机器人，query类别有......，你能正确理解query意思并正确分类。query为：“粉笔字临摹”，请判断其属于哪一类"
} ,
1:  {
role:  "bot",
utterance:  "教育培训"
} ,
2:  {
role:  "user",
utterance:  "你是一个query分类机器人，query类别......，你能正确理解query意思并正确分类。query为：“杀死比尔”，请判断其属于哪一类"
} ,
3:  {
role:  "bot",
utterance:  "影视动漫"
}
]
```
可以看出他的回答格式严格遵循我们训练的数据（llama2就不是🤮），且多次询问后都不会出现模型不稳定的问题，效果令人十分满意。
在测试集上进行验证后发现正确率果然达不到93%：
![image](https://github.com/user-attachments/assets/680ac357-5431-4b86-a2d1-0f57e9309a0f)
最后正确率稳定在了71%左右。但是我分析那些错误的分类发现有一些是因为所谓的正确答案错误而导致，因此实际正确率可能要更高，我决定将每个label的召回率、正确率等全部计算出来再做分析，不过这个要等到明天了。

## 其他
- 今天是百度消防演习日，在公司门口的宣传摊位上免费领了一个停车号码牌和一副扑克。
- 今天发的水果是一个橙子🍊。

## 总结
今天感觉真正训练了一个比较成功的模型，正确率虽然没有达到预期，但是我相信如果调整某些参数还能再次提升，当然了，训练数据集较小也是其中一个原因。再接再厉，加油🎉！

<!-- ##{"timestamp":1730991435}## -->